{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "430be55c-2ab8-40b4-9d55-dcac5a89eea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~11 (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~sutil (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ttpcore (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ttpx (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sentence-transformers in /user/aollagni/home/.local/lib/python3.12/site-packages (3.3.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (4.43.4)\n",
      "Requirement already satisfied: tqdm in /user/aollagni/home/.local/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /user/aollagni/home/.local/lib/python3.12/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /user/aollagni/home/.local/lib/python3.12/site-packages (from sentence-transformers) (1.6.0)\n",
      "Requirement already satisfied: scipy in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (0.27.0)\n",
      "Requirement already satisfied: Pillow in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /user/aollagni/home/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /user/aollagni/home/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /user/aollagni/home/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /user/aollagni/home/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /user/aollagni/home/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /user/aollagni/home/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.2.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~11 (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~sutil (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ttpcore (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ttpx (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~11 (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~sutil (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ttpcore (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ttpx (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sacremoses in /user/aollagni/home/.local/lib/python3.12/site-packages (0.1.1)\n",
      "Requirement already satisfied: regex in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from sacremoses) (2024.7.24)\n",
      "Requirement already satisfied: click in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from sacremoses) (8.1.7)\n",
      "Requirement already satisfied: joblib in /user/aollagni/home/.local/lib/python3.12/site-packages (from sacremoses) (1.4.2)\n",
      "Requirement already satisfied: tqdm in /user/aollagni/home/.local/lib/python3.12/site-packages (from sacremoses) (4.67.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~11 (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~sutil (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ttpcore (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ttpx (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~11 (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~sutil (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ttpcore (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ttpx (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /user/aollagni/home/.local/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /user/aollagni/home/.local/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /user/aollagni/home/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /user/aollagni/home/miniconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~11 (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~sutil (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ttpcore (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ttpx (/user/aollagni/home/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers\n",
    "!pip install sacremoses\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c692aa7e-bd78-40e6-8ab4-8afa708fea2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 09:51:55.834377: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-17 09:51:55.855807: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-17 09:51:55.875116: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-17 09:51:55.882636: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-17 09:51:55.895389: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-17 09:51:57.484731: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64b1074a-8485-4f28-b9ca-2283b2a5ebc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 09:53:31,866 - INFO - Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"pipeline.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "# Function to compute word embeddings in batches\n",
    "def get_word_embeddings_batch(texts, model, tokenizer, batch_size=32):\n",
    "    embeddings = []\n",
    "    logging.info(f\"Computing word embeddings in batches (batch size: {batch_size})...\")\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        tokens = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        outputs = model(**tokens.to(device))  # Ensure tokens are moved to the same device\n",
    "        batch_embeddings = outputs.last_hidden_state.mean(dim=1).detach().cpu().numpy()\n",
    "        embeddings.extend(batch_embeddings)\n",
    "        logging.info(f\"Generated embeddings shape: {embeddings.shape}\")\n",
    "    return embeddings\n",
    "\n",
    "# Function to compute sentence/message embeddings in batches\n",
    "def get_message_embeddings_batch(texts, model_name, batch_size=32):\n",
    "    model = SentenceTransformer(model_name).to(device)\n",
    "    embeddings = []\n",
    "    logging.info(f\"Computing sentence embeddings in batches (batch size: {batch_size})...\")\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        batch_embeddings = model.encode(batch_texts, show_progress_bar=True, device=str(device))  # Specify device\n",
    "        embeddings.extend(batch_embeddings)\n",
    "        logging.info(f\"Generated embeddings shape: {embeddings.shape}\")\n",
    "    return embeddings\n",
    "\n",
    "# Function to process DataFrame with embeddings\n",
    "def process_dataframe(df, models, batch_size=32):\n",
    "    \"\"\"\n",
    "    Process DataFrame to compute embeddings for 'TEXT' column.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        models (dict): Dictionary containing model and tokenizer pairs.\n",
    "        batch_size (int): Batch size for processing.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with additional embedding columns.\n",
    "    \"\"\"\n",
    "    if \"TEXT\" not in df.columns:\n",
    "        logging.error(\"The DataFrame does not contain a 'TEXT' column.\")\n",
    "        raise ValueError(\"The DataFrame does not contain a 'TEXT' column.\")\n",
    "\n",
    "    df[\"TEXT\"] = df[\"TEXT\"].fillna('').astype(str)\n",
    "    texts = df[\"TEXT\"].tolist()\n",
    "\n",
    "    for model_name, model_info in models.items():\n",
    "        model, tokenizer, message_model_name = model_info\n",
    "\n",
    "        # Word embeddings\n",
    "        logging.info(f\"Processing word embeddings for model: {model_name}\")\n",
    "        word_embeddings = get_word_embeddings_batch(texts, model, tokenizer, batch_size)\n",
    "        df[f\"{model_name}_Word_Embeddings\"] = word_embeddings\n",
    "\n",
    "        # Message embeddings\n",
    "        logging.info(f\"Processing message embeddings for model: {model_name}\")\n",
    "        message_embeddings = get_message_embeddings_batch(texts, message_model_name, batch_size)\n",
    "        df[f\"{model_name}_Message_Embeddings\"] = message_embeddings\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to prepare data\n",
    "def prepare_data(file_path, embedding_conversion):\n",
    "    if not os.path.exists(file_path):\n",
    "        logging.error(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "    logging.info(f\"Processing file: {file_path}\")\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    if embedding_conversion:\n",
    "        models = {\n",
    "            \"CamemBERT\": (\n",
    "                AutoModel.from_pretrained('camembert/camembert-large').to(device),\n",
    "                AutoTokenizer.from_pretrained('camembert/camembert-large'),\n",
    "                \"camembert/camembert-large\"\n",
    "                ),\n",
    "            \"Flaubert\": (\n",
    "                AutoModel.from_pretrained('flaubert/flaubert_large_cased').to(device),\n",
    "                AutoTokenizer.from_pretrained('flaubert/flaubert_large_cased'),\n",
    "                \"flaubert/flaubert_large_cased\"\n",
    "                ),\n",
    "            \"mBERT\": (\n",
    "                AutoModel.from_pretrained('bert-base-multilingual-cased').to(device),\n",
    "                AutoTokenizer.from_pretrained('bert-base-multilingual-cased'),\n",
    "                \"camembert/camembert-large\"\n",
    "                ),\n",
    "            \"CamemBERTa\": (\n",
    "                AutoModel.from_pretrained('almanach/camembertav2-base').to(device),\n",
    "                AutoTokenizer.from_pretrained('almanach/camembertav2-base'),\n",
    "                \"almanach/camembertav2-base\"\n",
    "                )\n",
    "        }\n",
    "\n",
    "        data = process_dataframe(data, models, batch_size=8)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8140a680-2365-487e-964a-7f20c866d3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 09:53:33,520 - INFO - Processing task: ABUSE at Data/majority_vote/sample.csv\n",
      "2024-12-17 09:53:33,523 - INFO - Processing file: Data/majority_vote/sample.csv\n",
      "Some weights of CamembertModel were not initialized from the model checkpoint at camembert/camembert-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "2024-12-17 09:53:41,704 - ERROR - Error processing task ABUSE: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 8.06 MiB is free. Including non-PyTorch memory, this process has 3.68 GiB memory in use. Of the allocated memory 3.49 GiB is allocated by PyTorch, and 130.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "\n",
    "tasks = ['ABUSE']\n",
    "embedding_conversion = True\n",
    "\n",
    "for task in tasks:\n",
    "    try:\n",
    "        file_path = \"Data/majority_vote/sample.csv\"\n",
    "        report_path = f\"reports/{task}_report.txt\"\n",
    "        #confusion_matrix_path = f\"reports/{task}_confusion_matrix.csv\" as to be a plot\n",
    "        fold_sizes_path = f\"reports/{task}_fold_sizes.csv\"\n",
    "        \n",
    "        logging.info(f\"Processing task: {task} at {file_path}\")\n",
    "        data = prepare_data(file_path, embedding_conversion)\n",
    "        \n",
    "        # # Initialize embeddings if required\n",
    "        # if embedding_conversion:\n",
    "        #     # Models and tokenizers\n",
    "        #     models = {\n",
    "        #         \"CamemBERT\": (\n",
    "        #             CamembertModel.from_pretrained('camembert/camembert-large').to(device),\n",
    "        #             CamembertTokenizer.from_pretrained('camembert/camembert-large'),\n",
    "        #             \"camembert/camembert-large\"\n",
    "        #         ),\n",
    "        #         \"Flaubert\": (\n",
    "        #             FlaubertModel.from_pretrained('flaubert/flaubert_large_cased').to(device),\n",
    "        #             FlaubertTokenizer.from_pretrained('flaubert/flaubert_large_cased'),\n",
    "        #             \"flaubert/flaubert_large_cased\"\n",
    "        #         )\n",
    "        #     }\n",
    "\n",
    "        #     # Process DataFrame\n",
    "        #     data = process_dataframe(data, models, batch_size=8)\n",
    "\n",
    "        # # Save the processed data\n",
    "        # output_path = os.path.join(file_path, 'processed_data.csv')\n",
    "        data.to_csv(file_path, index=False)\n",
    "        logging.info(f\"Processed data saved to {file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing task {task}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880629e2-baf9-46b1-93f6-91b12e6ffcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import logging\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from transformers import (\n",
    "    CamembertModel, CamembertTokenizer, AutoTokenizer, AutoModel\n",
    ")\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"pipeline.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Global Parameters\n",
    "BATCH_SIZE = 8\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Function to compute sentence embeddings in batches\n",
    "def get_message_embeddings_batch(texts, model_name, batch_size=BATCH_SIZE):\n",
    "    embeddings = []\n",
    "\n",
    "    try:\n",
    "        # Try to load as a SentenceTransformer model\n",
    "        model = SentenceTransformer(model_name).to(DEVICE)\n",
    "        tokenizer = None  # No need for separate tokenizer\n",
    "        use_transformers_directly = False\n",
    "    except Exception as e:\n",
    "        # Fall back to transformers if SentenceTransformer fails\n",
    "        logging.warning(f\"No SentenceTransformer model found with name '{model_name}'. Falling back to transformers: {e}\")\n",
    "        model = AutoModel.from_pretrained(model_name).to(DEVICE)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        use_transformers_directly = True\n",
    "\n",
    "    logging.info(f\"Computing embeddings with model '{model_name}' in batches...\")\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "\n",
    "        if not use_transformers_directly:\n",
    "            # Use SentenceTransformer for encoding\n",
    "            batch_embeddings = model.encode(batch_texts, show_progress_bar=True, device=str(DEVICE))\n",
    "        else:\n",
    "            # Use AutoModel and AutoTokenizer with word-level averaging\n",
    "            batch_embeddings = []\n",
    "            for text in batch_texts:\n",
    "                batch_embeddings.append(get_word_embeddings(text, model, tokenizer))\n",
    "\n",
    "        embeddings.extend(batch_embeddings)\n",
    "\n",
    "    # Convert list of embeddings to a numpy array\n",
    "    embeddings_array = np.vstack(embeddings)\n",
    "    logging.info(f\"Generated embeddings shape: {embeddings_array.shape}\")\n",
    "    return embeddings_array\n",
    "\n",
    "\n",
    "# Function to compute word-level averaged embeddings\n",
    "def get_word_embeddings(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "        # Word-level averaging\n",
    "        word_embeddings = last_hidden_state.squeeze()\n",
    "        message_embedding_word_avg = word_embeddings.mean(dim=0)\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    return message_embedding_word_avg.cpu().numpy()\n",
    "\n",
    "# Function to save results and print to file\n",
    "def print_and_save(message, file):\n",
    "    print(message, file=file)\n",
    "    logging.info(message)\n",
    "\n",
    "# Save confusion matrix to CSV\n",
    "def save_confusion_matrix(y_true, y_pred, output_path):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, index=[\"Class 0\", \"Class 1\"], columns=[\"Class 0\", \"Class 1\"])\n",
    "    cm_df.to_csv(output_path, index=True)\n",
    "    logging.info(f\"Confusion matrix saved to {output_path}\")\n",
    "\n",
    "# Save StratifiedKFold split sizes\n",
    "def save_fold_sizes(splits, output_path):\n",
    "    fold_data = [{\"Fold\": i + 1, \"Train Size\": len(train_idx), \"Test Size\": len(test_idx)} for i, (train_idx, test_idx) in enumerate(splits)]\n",
    "    pd.DataFrame(fold_data).to_csv(output_path, index=False)\n",
    "    logging.info(f\"StratifiedKFold split sizes saved to {output_path}\")\n",
    "\n",
    "# F1Evaluator Class for Metrics Calculation\n",
    "class F1Evaluator:\n",
    "    @staticmethod\n",
    "    def evaluate(classifier):\n",
    "        class_counts = Counter(classifier.Y_true)\n",
    "        total = len(classifier.Y_true)\n",
    "        proportions = {cls: round((count / total) * 100, 2) for cls, count in class_counts.items()}\n",
    "        metrics = {\n",
    "            \"micro\": f1_score(classifier.Y_true, classifier.predictions, average=\"micro\"),\n",
    "            \"macro\": f1_score(classifier.Y_true, classifier.predictions, average=\"macro\"),\n",
    "            \"weighted\": f1_score(classifier.Y_true, classifier.predictions, average=\"weighted\")\n",
    "        }\n",
    "        return f\"Metrics:\\nProportions: {proportions}\\nF1 Scores: {metrics}\"\n",
    "\n",
    "# Classifier Wrapper\n",
    "class Classifier:\n",
    "    def __init__(self, model, param_grid, model_name):\n",
    "        self.model = model\n",
    "        self.param_grid = param_grid\n",
    "        self.model_name = model_name\n",
    "        self.best_model = None\n",
    "        self.best_params = None\n",
    "        self.Y_true = None\n",
    "        self.predictions = None\n",
    "\n",
    "    def perform_grid_search(self, X_train, y_train, scaler, n_iter=50, random_state=42):\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "        random_search = RandomizedSearchCV(\n",
    "            self.model, self.param_grid, cv=inner_cv, scoring=\"f1_weighted\", n_iter=n_iter, random_state=random_state, n_jobs=-1\n",
    "        )\n",
    "        random_search.fit(X_train_scaled, y_train)\n",
    "        self.best_model = random_search.best_estimator_\n",
    "        self.best_params = random_search.best_params_\n",
    "\n",
    "    def evaluate_model(self, X_test, y_test, scaler):\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        self.predictions = self.best_model.predict(X_test_scaled)\n",
    "        self.Y_true = y_test\n",
    "\n",
    "# Function to prepare data\n",
    "def prepare_data(file_path, embedding_conversion):\n",
    "    if not os.path.exists(file_path):\n",
    "        logging.error(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "    logging.info(f\"Processing file: {file_path}\")\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    if embedding_conversion:\n",
    "        models = {\n",
    "            \"CamemBERT\": (\"camembert/camembert-large\"),\n",
    "            \"CamemBERTa\": (\"almanach/camembertav2-base\"),\n",
    "            \"mBERT\": (\"bert-base-multilingual-cased\")\n",
    "        }\n",
    "\n",
    "        for model_name, model_path in models.items():\n",
    "            data[f\"{model_name}_Message_Embeddings\"] = get_message_embeddings_batch(data[\"TEXT\"].fillna(\"\").tolist(), model_path)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Function to safely parse embedding strings into numpy arrays\n",
    "def parse_embedding(value):\n",
    "    try:\n",
    "        # Remove ellipses and ensure proper formatting\n",
    "        if isinstance(value, str):\n",
    "            cleaned_value = value.replace(\"...\", \"\").replace(\"\\n\", \"\").strip()\n",
    "            # Convert to numpy array directly using np.fromstring if it's a space-separated string\n",
    "            return np.fromstring(cleaned_value.strip(\"[]\"), sep=\" \")\n",
    "        else:\n",
    "            logging.error(f\"Non-string value encountered: {value}\")\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to parse embedding: {value} - {e}\")\n",
    "        return np.array([])  # Return an empty array on failure\n",
    "\n",
    "# Main Execution\n",
    "tasks = [\"ABUSE\", \"B_POLARITY\", \"POR\"]\n",
    "embedding_conversion = True\n",
    "\n",
    "for task in tasks:\n",
    "    try:\n",
    "        file_path = \"Data/majority_vote/annotations_all_binary.csv\"\n",
    "        report_path = f\"reports/{task}_report.txt\"\n",
    "        confusion_matrix_path = f\"reports/{task}_confusion_matrix.csv\"\n",
    "        fold_sizes_path = f\"reports/{task}_fold_sizes.csv\"\n",
    "\n",
    "        data = prepare_data(file_path, embedding_conversion)\n",
    "\n",
    "        if data is None:\n",
    "            continue\n",
    "\n",
    "        with open(report_path, \"w\") as report_file:\n",
    "            for embedding in [col for col in data.columns if \"CamemBERT_Message_Embeddings\" in col]:\n",
    "                print(np.array(data[embedding][0]).tolist())\n",
    "                features = np.array(data[embedding].apply(parse_embedding).tolist())\n",
    "                labels = data[task].dropna().astype(int).to_numpy()\n",
    "\n",
    "                param_grids = {\n",
    "                    \"SVM\": {'C': [0.1, 1], 'kernel': ['linear', 'rbf']},\n",
    "                    \"Decision Tree\": {'max_depth': [3, 5], 'criterion': ['gini', 'entropy']},\n",
    "                    \"Random Forest\": {'n_estimators': [10, 50], 'max_depth': [5, 10]},\n",
    "                    \"Logistic Regression\": {'C': [0.1, 1], 'penalty': ['l2']}\n",
    "                }\n",
    "\n",
    "                classifiers = [\n",
    "                    Classifier(SVC(probability=True), param_grids[\"SVM\"], \"SVM\"),\n",
    "                    Classifier(DecisionTreeClassifier(), param_grids[\"Decision Tree\"], \"Decision Tree\"),\n",
    "                    Classifier(RandomForestClassifier(), param_grids[\"Random Forest\"], \"Random Forest\"),\n",
    "                    Classifier(LogisticRegression(), param_grids[\"Logistic Regression\"], \"Logistic Regression\")\n",
    "                ]\n",
    "\n",
    "                outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "                splits = list(outer_cv.split(features, labels))\n",
    "                save_fold_sizes(splits, fold_sizes_path)\n",
    "\n",
    "                for clf in classifiers:\n",
    "                    clf.perform_grid_search(features, labels, StandardScaler())\n",
    "                    clf.evaluate_model(features, labels, StandardScaler())\n",
    "                    evaluator = F1Evaluator()\n",
    "                    metrics = evaluator.evaluate(clf)\n",
    "                    print_and_save(metrics, report_file)\n",
    "\n",
    "                    # Save confusion matrix of the best model\n",
    "                    save_confusion_matrix(clf.Y_true, clf.predictions, confusion_matrix_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing task '{task}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6b15c-0481-4f67-b705-cb80a5500374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
