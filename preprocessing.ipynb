{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d961b459-f1db-45d0-94c4-dbd1909ffbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have been processed and renamed. The original filenames are stored in original_filenames.txt.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory containing the files\n",
    "directory = 'Data/majority_vote'\n",
    "output_file = 'original_filenames.txt'\n",
    "\n",
    "# List all files in the directory\n",
    "files = sorted([f for f in os.listdir(directory) if f.endswith('.xlsx') and not f.startswith('~$')])\n",
    "\n",
    "# Open a file to write the original and new filenames\n",
    "with open(os.path.join(directory, output_file), 'w') as f:\n",
    "    # Iterate through each file\n",
    "    for i, file in enumerate(files):\n",
    "        original_file_path = os.path.join(directory, file)\n",
    "        \n",
    "        # Define new file name\n",
    "        new_file_name = f'conv{i+1}.xlsx'\n",
    "        new_file_path = os.path.join(directory, new_file_name)\n",
    "        \n",
    "        # Rename the file\n",
    "        os.rename(original_file_path, new_file_path)\n",
    "        \n",
    "        # Write the mapping of new file name to original file name\n",
    "        f.write(f'{new_file_name} ---> {file}\\n')\n",
    "        \n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(new_file_path, engine='openpyxl', dtype=str)\n",
    "        \n",
    "        # Replace NaN values with 'NULL'\n",
    "        df.fillna('NULL', inplace=True)\n",
    "        \n",
    "        # Change the ID column values\n",
    "        df['ID'] = ['mess' + str(j+1) for j in range(len(df))]\n",
    "        \n",
    "        # Save the corrected dataframe back to the Excel file\n",
    "        df.to_excel(new_file_path, index=False, engine='openpyxl')\n",
    "\n",
    "print(\"All files have been processed and renamed. The original filenames are stored in original_filenames.txt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4c52d7-fe91-46fa-b4e6-25c9ef3a3c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have been processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Specify the directory containing the files\n",
    "directory = 'Data/majority_vote'\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Function to check if a string is in a time format\n",
    "def is_time_format(s):\n",
    "    time_only_pattern = re.compile(r'^\\d{2}:\\d{2}:\\d{2}$')\n",
    "    date_time_pattern = re.compile(r'^\\[\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\]$')\n",
    "    return bool(time_only_pattern.match(s)) or bool(date_time_pattern.match(s))\n",
    "\n",
    "# Function to extract time from various time formats, including AM/PM formats and brackets\n",
    "def extract_time(s):\n",
    "    # Remove any surrounding brackets\n",
    "    s = re.sub(r'[\\[\\]]', '', s)\n",
    "    \n",
    "    # Convert AM/PM time to 24-hour format\n",
    "    try:\n",
    "        time_obj = datetime.strptime(s, '%I:%M:%S %p')\n",
    "        return time_obj.strftime('%H:%M:%S')\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    # Extract time from string\n",
    "    time_pattern = re.compile(r'\\d{2}:\\d{2}:\\d{2}')\n",
    "    match = time_pattern.search(s)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return s  # If no match, return the original string\n",
    "\n",
    "# Function to normalize name based on the given rules\n",
    "def normalize_name(s):\n",
    "    # Remove angle brackets\n",
    "    s = re.sub(r'[<>]', '', s)\n",
    "    # Remove underscores or hyphens and take the first part\n",
    "    s = re.split(r'[_-]', s)[0]\n",
    "    # Remove @ symbol at the beginning\n",
    "    s = re.sub(r'^@', '', s)\n",
    "    # Extract the first word if it starts with @\n",
    "    if '@' in s:\n",
    "        s = re.split(r'@', s)[1]\n",
    "    # Remove numeric characters\n",
    "    s = re.sub(r'\\d', '', s)\n",
    "    return s\n",
    "\n",
    "def correct_columns(file_path):\n",
    "    try:\n",
    "        # Read the Excel file, treating \"NULL\" as a string rather than NaN\n",
    "        df = pd.read_excel(file_path, engine='openpyxl', dtype=str)\n",
    "        df.fillna('NULL', inplace=True)  # Replace NaN values with 'NULL'\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Check if the columns are swapped\n",
    "    if all(is_time_format(str(x)) for x in df['NAME']) and not all(is_time_format(str(x)) for x in df['TIME']):\n",
    "        # Swap the values in NAME and TIME columns\n",
    "        df[['NAME', 'TIME']] = df[['TIME', 'NAME']]\n",
    "\n",
    "    # Normalize the TIME column\n",
    "    df['TIME'] = df['TIME'].apply(extract_time)\n",
    "\n",
    "    # Normalize the NAME column\n",
    "    df['NAME'] = df['NAME'].apply(normalize_name)\n",
    "\n",
    "    # Ensure columns are in the correct order\n",
    "    correct_order = ['ID', 'NAME', 'TIME', 'TEXT', 'ROLE', 'HATE', 'TARGET', 'VERBAL_ABUSE', 'INTENTION', 'CONTEXT','SENTIMENT']\n",
    "    df = df[correct_order]\n",
    "\n",
    "    # Save the corrected dataframe back to the Excel file\n",
    "    try:\n",
    "        df.to_excel(file_path, index=False, engine='openpyxl')\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {file_path}: {e}\")\n",
    "\n",
    "# Iterate through each file and correct the columns if necessary\n",
    "for file in files:\n",
    "    if file.endswith('.xlsx') and not file.startswith('~$'):  # Ensure we're only processing Excel files and ignore temporary files\n",
    "        file_path = os.path.join(directory, file)\n",
    "        correct_columns(file_path)\n",
    "\n",
    "print(\"All files have been processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2098eafc-2c53-4d11-be03-5096d7c0a84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID column updated in all Excel files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory containing the files\n",
    "directory = 'Data/majority_vote'\n",
    "\n",
    "# List all files in the directory\n",
    "files = sorted([f for f in os.listdir(directory) if f.endswith('.xlsx') and not f.startswith('~$')])\n",
    "\n",
    "# Process each file\n",
    "for file in files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    \n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(file_path, engine='openpyxl', dtype=str)\n",
    "    \n",
    "    # Replace NaN values with 'NULL'\n",
    "    df.fillna('NULL', inplace=True)\n",
    "    \n",
    "    # Change the ID column values\n",
    "    df['ID'] = f'{file[:-5]}_mess' + (df.index + 1).astype(str)\n",
    "    \n",
    "    # Save the corrected dataframe back to the Excel file\n",
    "    df.to_excel(file_path, index=False, engine='openpyxl')\n",
    "\n",
    "print(\"ID column updated in all Excel files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c49e81c7-3ee6-4a66-bfb6-60953c15c742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved extracted data to Data/majority_vote/annotations_all.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def extract_annotation(directory, fields):\n",
    "    extracted_data = []\n",
    "    # Dynamically retrieve all .xlsx files in the specified directory\n",
    "    filenames = glob.glob(os.path.join(directory, '*.xlsx'))\n",
    "    \n",
    "    if not filenames:\n",
    "        print(f\"No Excel files found in the directory {directory}.\")\n",
    "        return pd.DataFrame(columns=fields)\n",
    "\n",
    "    for filepath in filenames:\n",
    "        filename = os.path.basename(filepath)\n",
    "        try:\n",
    "            df = pd.read_excel(filepath)\n",
    "            df.fillna('NULL', inplace=True)  # Replace NaN values with 'NULL'\n",
    "            if set(fields).issubset(df.columns):\n",
    "                extracted_data.append(df[fields])\n",
    "            else:\n",
    "                missing_fields = set(fields) - set(df.columns)\n",
    "                print(f\"File {filename} is missing fields: {missing_fields}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process file {filename} due to error: {e}\")\n",
    "\n",
    "    if extracted_data:\n",
    "        return pd.concat(extracted_data, ignore_index=True)\n",
    "    else:\n",
    "        print(\"No valid data extracted from the files.\")\n",
    "        return pd.DataFrame(columns=fields)\n",
    "\n",
    "\n",
    "\n",
    "combined_data = extract_annotation(f'Data/majority_vote/', ['ID', 'NAME', 'TIME', 'TEXT', 'ROLE', 'HATE', 'TARGET', 'VERBAL_ABUSE', 'INTENTION', 'CONTEXT','SENTIMENT'])\n",
    "if not combined_data.empty:\n",
    "    \n",
    "    output_path = f'Data/majority_vote/annotations_all.csv'\n",
    "    combined_data.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Saved extracted data to {output_path}\")\n",
    "else:\n",
    "    print(f\"No data extracted for target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50b1af09-7ad5-4c7a-921a-6f832b2c3795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique names and their IDs have been saved to Data/majority_vote/unique_names.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Function to extract unique names from a directory\n",
    "def extract_unique_names(directory):\n",
    "    unique_names = set()\n",
    "    \n",
    "    # Specify the filename explicitly (assuming it is a CSV file)\n",
    "    filename = \"annotations_all.csv\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if os.path.exists(filepath):\n",
    "        try:\n",
    "            # Use pd.read_csv for CSV files\n",
    "            df = pd.read_csv(filepath)\n",
    "            \n",
    "            # Check if 'NAME' column exists\n",
    "            if 'NAME' in df.columns:\n",
    "                unique_names.update(df['NAME'].dropna().unique())\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {filepath}: {e}\")\n",
    "    else:\n",
    "        print(f\"File {filename} does not exist in the directory {directory}.\")\n",
    "    \n",
    "    return unique_names\n",
    "\n",
    "# Extract unique names from the directory\n",
    "unique_names = extract_unique_names(\"Data/majority_vote\")\n",
    "all_unique_names = list(unique_names)\n",
    "\n",
    "# Generate 5-digit unique IDs for each name\n",
    "name_to_id = {name: f'{random.randint(10000, 99999)}' for name in all_unique_names}\n",
    "\n",
    "# Save the unique names and their IDs to a text file\n",
    "unique_names_file = os.path.join(\"Data/majority_vote\", 'unique_names.txt')\n",
    "with open(unique_names_file, 'w') as file:\n",
    "    for name, id_ in name_to_id.items():\n",
    "        file.write(f'{name},{id_}\\n')\n",
    "\n",
    "print(f\"Unique names and their IDs have been saved to {unique_names_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ae8c4c9-5f9a-4c70-836b-f14ca4762c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to transform the Hate field and add new fields\n",
    "def LabelTransformation(directory):\n",
    "    # Specify the file name\n",
    "    filename = \"annotations_all.csv\"\n",
    "    file_path = os.path.join(directory, filename)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File {filename} does not exist in the directory {directory}.\")\n",
    "        return\n",
    "\n",
    "    # Read the file as a CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.fillna('NULL', inplace=True)  # Replace NaN values with 'NULL'\n",
    "\n",
    "    # Remove rows where 'ROLE' is 'conciliator'\n",
    "    df = df[df['ROLE'] != 'conciliator']\n",
    "\n",
    "    # Add the new \"Hate_Abuse\" field\n",
    "    df['ABUSE'] = df['HATE'].apply(lambda x: 'YES' if x in ['OAG', 'CAG'] else 'NO')\n",
    "\n",
    "    # Add the new \"Behaviour Polarity\" field\n",
    "    df['B_POLARITY'] = df['INTENTION'].apply(lambda x: 'POS' if x in ['DFN', 'CNS', 'CR', 'EMP', 'OTH'] else 'NAG')\n",
    "\n",
    "    # Add the new \"Participant Role Detection\" field\n",
    "    df['POR'] = df['ROLE'].apply(\n",
    "        lambda x: 'VS' if x in ['victim', 'victim_support'] else ('BS' if x in ['bully', 'bully_support'] else 'NULL')\n",
    "    )\n",
    "\n",
    "    # Save the updated DataFrame back to a CSV file\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "# Call the function\n",
    "LabelTransformation('Data/majority_vote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "023ad661-f3c9-4285-96cf-1bc24215ff5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully with binary transformations!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21919/3841962762.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['ABUSE'] = df['ABUSE'].replace({'YES': 1, 'NO': 0}).fillna(-1).astype(int)\n",
      "/tmp/ipykernel_21919/3841962762.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['B_POLARITY'] = df['B_POLARITY'].replace({'POS': 0, 'NAG': 1}).fillna(-1).astype(int)\n",
      "/tmp/ipykernel_21919/3841962762.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['POR'] = df['POR'].replace({'BS': 1, 'VS': 0}).fillna(-1).astype(int)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('Data/majority_vote/annotations_all.csv')\n",
    "\n",
    "# Handle non-finite values by filling NaN with a default value (e.g., 0 or another placeholder)\n",
    "# ABUSE\n",
    "df['ABUSE'] = df['ABUSE'].replace({'YES': 1, 'NO': 0}).fillna(-1).astype(int)\n",
    "    \n",
    "# B_POLARITY\n",
    "df['B_POLARITY'] = df['B_POLARITY'].replace({'POS': 0, 'NAG': 1}).fillna(-1).astype(int)\n",
    "\n",
    "# POR\n",
    "df['POR'] = df['POR'].replace({'BS': 1, 'VS': 0}).fillna(-1).astype(int)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(\"Data/majority_vote/annotations_all_binary.csv\", index=False)\n",
    "\n",
    "print(\"File saved successfully with binary transformations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e825924-a1c0-4b2c-a3c4-1795bb1e35c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
